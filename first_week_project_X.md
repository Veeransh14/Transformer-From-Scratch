# Transformer From Scratch 


# Course 1-
# Week 1- Introduction

Before starting with our project it is necessary to know what its based on.Our project deals with concepts of deep learning and ML without which our course cannot be started.
DL deep learning is nowadays used in many businesses for management and other purposes.It is used for online advertisements self-driving cars face recognition and many such other complex algorithms.


# In this course we would be working on the following topics-

1.Neural Networks and Deep Learning 

2.Improving deep neural networks hyperparameter tuning regularization and optimization 

3.Structuring your machine learning project 

4.Convolutional Neural Networks 

5.Natural Language Processing Building Sequence Models

Let's consider an example of a house your we want to find the price of the house with respect to the size of the house your way would plot a graph where the price of the house would be displayed on the y axis and the size of the house would be displayed on x-axis here we would take 5 to 6 inputs from the users that is the number of house and display its price accordingly to its size to find the average or rough preduction we can easily find it by linear regression by drawing a line such that it passes through the nearest of all points.

This is practically possible for small data sets and small functions but when we are dealing with large data sets and large functions where there are many different constraints and that time it's difficult for the neural networks to learn and understand things with help of linear regression since is not so useful for dealing with so many constriants.

Here comes are concept of neural networks which basically works on the principle of perceptrons here as in our example the price of house could not only depend upon the size but would also depend upon number of bedrooms its location in the city and the facilities and ammenities available near it so for calculating this problem be cannot use linear regression instead we would be using neural networks here constraint would be given a particular weight and they would be connected with each other directly or indirectly in a neural network and we would be accepting an input from the user which would be noted by the letter X these are the different constraints that would be required in our problem.

These constraints are connected to a set of neurons the set of neurons are connected to another set of data which are again connected to neurons and this branching and sub branching goes on and on later this sub branching gets converted to branching and is branching later on makes us reach or give a final output by denoted by letter Y.

# SIMPLIFIED EXPLAINATION:-

Data sets-------------->Neurons-------->Another Data sets------>Neurons---------->Output(Y)
Input/constraints(X)    sub branchings                    final branchings      


# Types of Neural Networks

There are three types of neural networks based on structure workinmg and complexity of data used
1.Standard neural networks 
2.Convolutional Neural Networks
3.Recurrent neural networks

# There is two type of data-
 Structure data and unstructured Data.Structure data is in form of tabular or some graph type such that Its easy to infer out conclusions from it however it's difficult to conclude from unstructured Data because here the data is not systematically arranged as a result it becomes difficult for the computer to understand.This problem was being faced since many years however due to the advancement of Technology and the arrival of neural networks have revolutionarized this problem because of this it has created many opportunities for interesting applications such as speech recognition image recognition and natural language processing of text.


# Scale drives deep learning process 
To understand a basic concept of how a model of machine learning works let's plot a graph where amount of data represented by M is on x-axis and performance of that model is plotted on y axis.

Here we plot graph of different neural networks starting with basic learning algorithms like regression it is observed that with increase in amount of data the performance increases for some time however after a certain value saturation is arrived.
In small neural networks the saturation of performance is arrived shortly however in medium neural networks this saturation of performance of the model arise little late.In large neural networks the performance keeps on increasing with increasing amount of data and saturation is hardly observed this tells that large noodle networks have more ability to produce efficient outcomes as compared to other neural network because they can deal with large amount of data and similarly perform well.
When working with Limited amount of data it is observed that all neural networks usually have same performance here the performance basically depends upon the algorithm used and other engineering skills involved in the problem solving


# Our scale drives deep learning process involves 3 main step-
1.data 
2.computation 
3.algorithm 
the computation part is very important because it mainly works on 3 steps Idea experiment and code.Idea experiment and code that is these three step work in a loop continuously to produce better results and train the model.These three steps help us to design new and efficient algorithms for a given model.
These three steps of training are very iterative in approach.



